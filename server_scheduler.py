"""
24/7 daily video generator/uploader runner.

Behavior:
- Starts daily cycles at midnight Pacific Time
- Once every 24 hours: generate a daily "pack" of videos into a non-output folder.
- Each daily pack goes under DAILY_PACKS_DIR/YYYYMMDD/.
- Generate videos until credits/quota are exhausted (or generation fails).
- Upload all videos for the day at evenly spaced intervals over 24h.
- Do not start the next day's generation until all uploads for the current pack finish.
- Keep only the last 3 daily packs (delete anything older than 2 days).
"""

from __future__ import annotations

import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List
import argparse

try:
    from zoneinfo import ZoneInfo
except ImportError:
    # Python < 3.9 fallback
    try:
        import pytz
        ZoneInfo = None  # Will use pytz instead
    except ImportError:
        raise ImportError(
            "Timezone support requires Python 3.9+ (zoneinfo) or pytz package.\n"
            "Install pytz: pip install pytz"
        )

from main_pipeline import VideoPipeline
from src.config import BASE_DIR, YOUTUBE_PRIVACY_STATUS
from src.youtube_uploader import upload_video_to_youtube


DAILY_PACKS_DIR = BASE_DIR / "daily_packs"
DAILY_PACKS_DIR.mkdir(exist_ok=True)

PACK_RETENTION_DAYS = 3  # keep today + previous 2 days
RUN_INTERVAL_HOURS = 24
MANIFEST_NAME = "manifest.json"

# Pacific Time zone (handles PST/PDT automatically)
if ZoneInfo:
    PACIFIC_TZ = ZoneInfo("America/Los_Angeles")
else:
    PACIFIC_TZ = pytz.timezone("America/Los_Angeles")


def _now_pacific() -> datetime:
    """Get current time in Pacific Time."""
    if ZoneInfo:
        return datetime.now(PACIFIC_TZ)
    else:
        return datetime.now(pytz.UTC).astimezone(PACIFIC_TZ)


def _today_str() -> str:
    """Get today's date string in Pacific Time."""
    return _now_pacific().strftime("%Y%m%d")


def _next_midnight_pacific() -> datetime:
    """Calculate next midnight Pacific Time."""
    now = _now_pacific()
    
    if ZoneInfo:
        # Using zoneinfo (Python 3.9+)
        midnight_today = now.replace(hour=0, minute=0, second=0, microsecond=0)
        if now >= midnight_today:
            midnight_today += timedelta(days=1)
    else:
        # Using pytz
        today = now.date()
        midnight_today = PACIFIC_TZ.localize(
            datetime(today.year, today.month, today.day, 0, 0, 0)
        )
        if now >= midnight_today:
            tomorrow = today + timedelta(days=1)
            midnight_today = PACIFIC_TZ.localize(
                datetime(tomorrow.year, tomorrow.month, tomorrow.day, 0, 0, 0)
            )
    
    return midnight_today


def _load_manifest(pack_dir: Path) -> Dict:
    manifest_path = pack_dir / MANIFEST_NAME
    if manifest_path.exists():
        with open(manifest_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"date": pack_dir.name, "videos": []}


def _save_manifest(pack_dir: Path, manifest: Dict) -> None:
    manifest_path = pack_dir / MANIFEST_NAME
    with open(manifest_path, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2, ensure_ascii=False)


def _is_credit_error(err: Exception) -> bool:
    """Check if error is related to API quota/credits."""
    from src.youtube_uploader import QuotaExceededError
    
    # Check for YouTube quota errors
    if isinstance(err, QuotaExceededError):
        return True
    
    msg = str(err).lower()
    keywords = ["quota", "credit", "insufficient", "limit", "billing", "exceeded", "rate limit"]
    return any(k in msg for k in keywords)


def _is_tts_error(err: Exception) -> bool:
    """Check if error is related to TTS (any TTS-related error, not just speech generation)."""
    # Check if error originates from TTS module by examining traceback
    try:
        tb_str = ''.join(traceback.format_exception(type(err), err, err.__traceback__))
        if 'tts_narration' in tb_str.lower() or 'generate_narration' in tb_str.lower():
            return True
    except:
        pass
    
    # Check error message for TTS-related keywords
    msg = str(err).lower()
    keywords = [
        'tts',  # Any mention of TTS
        'text-to-speech',
        'text to speech',
        'narration',
        'audio generation',
        'generate audio',
        'speech',
        'gemini.*tts',  # Gemini TTS errors
        'no audio content',
        'audio.*failed',
        'narration.*failed',
        'generate.*failed',
        'gemini api keys failed',
        'no gemini api keys'
    ]
    
    # Check if any keyword appears in the error message
    for keyword in keywords:
        if keyword in msg:
            return True
    
    # Check error type - if it's a RuntimeError or ValueError from TTS context
    if isinstance(err, (RuntimeError, ValueError, ImportError)):
        # Check if it's likely a TTS error (not a generic error)
        if any(k in msg for k in ['gemini', 'api key', 'audio', 'narration', 'tts']):
            return True
    
    return False


def _cleanup_old_packs() -> None:
    """Delete packs older than PACK_RETENTION_DAYS."""
    cutoff = _now_pacific().date() - timedelta(days=PACK_RETENTION_DAYS - 1)
    for item in DAILY_PACKS_DIR.iterdir():
        if not item.is_dir():
            continue
        try:
            pack_date = datetime.strptime(item.name, "%Y%m%d").date()
        except ValueError:
            continue
        if pack_date < cutoff:
            print(f"ðŸ§¹ Removing old pack: {item}")
            for child in item.iterdir():
                if child.is_file():
                    child.unlink(missing_ok=True)
                elif child.is_dir():
                    for sub in child.rglob("*"):
                        if sub.is_file():
                            sub.unlink(missing_ok=True)
                    subdirs = sorted([d for d in child.rglob("*") if d.is_dir()], reverse=True)
                    for d in subdirs:
                        d.rmdir()
                    child.rmdir()
            item.rmdir()


def _ensure_dirs(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def _upload_video(video_path: str, metadata_path: str, privacy_status: str = "private") -> Dict:
    """
    Upload video to YouTube using metadata file.
    
    Args:
        video_path: Path to video file
        metadata_path: Path to metadata.json file
        privacy_status: YouTube privacy status (private, unlisted, public)
    
    Returns:
        Dict with upload result (video_id, video_url, etc.)
    """
    return upload_video_to_youtube(
        video_path=video_path,
        metadata_path=metadata_path,
        privacy_status=privacy_status
    )


def _schedule_uploads(manifest: Dict, pack_dir: Path, upload_all_now: bool = False) -> None:
    """Upload videos for the pack.
    
    If upload_all_now is True, upload immediately without spacing.
    Otherwise, spread uploads evenly across 24h (min 1 hour between uploads).
    """
    videos = manifest.get("videos", [])
    pending = [v for v in videos if not v.get("uploaded")]
    if not pending:
        print("âœ“ All videos already uploaded for this pack.")
        return

    # Upload immediately if requested
    if upload_all_now:
        interval_seconds = 0
    else:
        # Spread uploads evenly over 24 hours with a minimum 1-hour gap
        # YouTube default quota: ~6 uploads/day (1,600 units per upload, 10,000 units/day)
        min_interval_seconds = 3600  # 1 hour minimum between uploads
        ideal_interval = 24 * 3600 / max(1, len(videos))
        interval_seconds = max(ideal_interval, min_interval_seconds)
    
    start_time = _now_pacific()

    for idx, video in enumerate(pending):
        if interval_seconds > 0:
            scheduled_time = start_time + timedelta(seconds=interval_seconds * idx)
            wait_seconds = (scheduled_time - _now_pacific()).total_seconds()
            if wait_seconds > 0:
                print(f"â³ Waiting {wait_seconds/60:.1f} minutes until next upload slot...")
                time.sleep(wait_seconds)

        try:
            # Upload video to YouTube
            upload_result = _upload_video(
                video_path=video["video_path"],
                metadata_path=video["metadata_path"],
                privacy_status=YOUTUBE_PRIVACY_STATUS
            )
            
            # Update manifest with upload info
            video["uploaded"] = True
            video["uploaded_at"] = _now_pacific().isoformat()
            video["youtube_video_id"] = upload_result.get("video_id")
            video["youtube_url"] = upload_result.get("video_url")
            _save_manifest(pack_dir, manifest)
            print(f"âœ“ Uploaded {video['video_path']} â†’ {upload_result.get('video_url')}")
        except Exception as e:
            print(f"âŒ Upload failed for {video['video_path']}: {e}")
            import traceback
            traceback.print_exc()
            _save_manifest(pack_dir, manifest)
            
            # Check if it's a quota error - stop all uploads and wait for next day
            if _is_credit_error(e):
                print("âš ï¸  YouTube API quota exceeded. Stopping uploads for today.")
                print("   Remaining videos will be uploaded tomorrow when quota resets.")
                break
            
            # For other errors, stop to avoid cascading issues; retry next cycle
            break


def _generate_daily_pack(pack_dir: Path) -> Dict:
    """Generate videos until credits are exhausted or generation fails."""
    _ensure_dirs(pack_dir)
    manifest = _load_manifest(pack_dir)
    pipeline = VideoPipeline(output_dir=pack_dir)

    consecutive_failures = 0
    max_consecutive_failures = 5  # Stop after 5 consecutive failures (non-TTS errors)
    
    while True:
        try:
            result = pipeline.generate_video()
            if not result.get("success"):
                err_msg = result.get("error", "unknown error")
                err_exception = Exception(err_msg)
                print(f"âš ï¸  Generation failed: {err_msg}")
                
                # Check if it's a credit/quota error - stop immediately
                if _is_credit_error(err_exception):
                    print("âš ï¸  Stopping generation due to credit/quota exhaustion.")
                    break
                
                # Check if it's a TTS error - continue trying with different posts
                if _is_tts_error(err_exception):
                    consecutive_failures = 0  # Reset counter for TTS errors
                    print("âš ï¸  TTS generation failed after retries. Trying next post...")
                    time.sleep(2)  # Brief delay before next attempt
                    continue
                
                # Other errors - increment failure counter
                consecutive_failures += 1
                if consecutive_failures >= max_consecutive_failures:
                    print(f"âš ï¸  Stopping generation after {max_consecutive_failures} consecutive failures.")
                    break
                else:
                    print(f"âš ï¸  Non-TTS error ({consecutive_failures}/{max_consecutive_failures}). Trying next post...")
                    time.sleep(2)  # Brief delay before next attempt
                    continue

            # Success! Reset failure counter and add video to manifest
            consecutive_failures = 0
            manifest["videos"].append(
                {
                    "video_path": result["video_path"],
                    "metadata_path": result["metadata_path"],
                    "output_dir": result["output_dir"],
                    "uploaded": False,
                    "uploaded_at": None,
                    "generated_at": _now_pacific().isoformat(),
                }
            )
            _save_manifest(pack_dir, manifest)
            print(f"ðŸŽ¥ Generated video: {result['video_path']}")
        except Exception as e:
            print(f"âŒ Generation exception: {e}")
            
            # Check if it's a credit/quota error - stop immediately
            if _is_credit_error(e):
                print("âš ï¸  Stopping generation due to suspected credit/quota exhaustion.")
                break
            
            # Check if it's a TTS error - continue trying
            if _is_tts_error(e):
                consecutive_failures = 0  # Reset counter for TTS errors
                print("âš ï¸  TTS generation failed. Trying next post...")
                time.sleep(2)  # Brief delay before next attempt
                continue
            
            # Other exceptions - increment failure counter
            consecutive_failures += 1
            if consecutive_failures >= max_consecutive_failures:
                print(f"âš ï¸  Stopping generation after {max_consecutive_failures} consecutive exceptions.")
                break
            else:
                print(f"âš ï¸  Exception ({consecutive_failures}/{max_consecutive_failures}). Trying next post...")
                time.sleep(2)  # Brief delay before next attempt
                continue

    return manifest


def run_forever(start_now: bool = False, upload_all_now: bool = False) -> None:
    """Main loop: daily generation + scheduled uploads, forever."""
    # Wait until next midnight Pacific Time before starting (unless start_now is True)
    if not start_now:
        next_midnight = _next_midnight_pacific()
        now = _now_pacific()
        wait_seconds = (next_midnight - now).total_seconds()
        
        if wait_seconds > 0:
            wait_hours = wait_seconds / 3600
            print(f"â° Waiting until midnight Pacific Time ({next_midnight.strftime('%Y-%m-%d %H:%M:%S %Z')})")
            print(f"   Current Pacific Time: {now.strftime('%Y-%m-%d %H:%M:%S %Z')}")
            print(f"   Waiting {wait_hours:.2f} hours...")
            time.sleep(wait_seconds)
    else:
        print("â–¶ï¸ start_now enabled: beginning immediately, next cycles at Pacific midnight.")
        now = _now_pacific()
        print(f"   Current Pacific Time: {now.strftime('%Y-%m-%d %H:%M:%S %Z')}")
        
    while True:
        cycle_start = _now_pacific()
        today = _today_str()
        pack_dir = DAILY_PACKS_DIR / today

        print(f"\n=== Daily cycle start for {today} (Pacific Time: {cycle_start.strftime('%Y-%m-%d %H:%M:%S %Z')}) ===")
        _cleanup_old_packs()

        manifest = _load_manifest(pack_dir)
        if not manifest.get("videos"):
            print("No existing videos for today. Generating pack...")
            manifest = _generate_daily_pack(pack_dir)
        else:
            print(f"Found existing pack with {len(manifest['videos'])} video(s). Resuming uploads.")

        if not manifest.get("videos"):
            print("Nothing to upload for this pack.")
        else:
            _schedule_uploads(manifest, pack_dir, upload_all_now=upload_all_now)

        # Sleep until next midnight Pacific Time
        next_midnight = _next_midnight_pacific()
        now = _now_pacific()
        sleep_seconds = (next_midnight - now).total_seconds()
        if sleep_seconds > 0:
            wait_hours = sleep_seconds / 3600
            print(f"ðŸ›Œ Sleeping {wait_hours:.2f} hours until next midnight Pacific Time ({next_midnight.strftime('%Y-%m-%d %H:%M:%S %Z')})...")
            time.sleep(sleep_seconds)


def main():
    parser = argparse.ArgumentParser(description="Daily video generator/uploader scheduler")
    parser.add_argument(
        "--start-now",
        action="store_true",
        help="Start immediately (skip initial wait until Pacific midnight). Subsequent cycles still start at midnight PT."
    )
    parser.add_argument(
        "--upload-all-now",
        action="store_true",
        help="Upload all videos immediately without spacing (ignores 24h distribution)."
    )
    args = parser.parse_args()
    run_forever(start_now=args.start_now, upload_all_now=args.upload_all_now)


if __name__ == "__main__":
    main()


